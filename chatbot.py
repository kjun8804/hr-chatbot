import streamlit as st
import os
import json
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain.retrievers.document_compressors import EmbeddingsFilter
from langchain.retrievers import ContextualCompressionRetriever
from langchain.chains.llm import LLMChain
from langchain.chains.combine_documents.refine import RefineDocumentsChain
from notion_client import Client
from notion_client.helpers import collect_paginated_api
from google.oauth2 import service_account
from googleapiclient.discovery import build
from langchain.vectorstores import DocArrayInMemorySearch

# âœ… API í‚¤
openai_api_key = st.secrets["OPENAI_API_KEY"]
notion = Client(auth=st.secrets["NOTION_TOKEN"])
notion_page_id = st.secrets["NOTION_PAGE_ID"]
SPREADSHEET_ID = st.secrets["GOOGLE_SHEET_ID"]

# âœ… ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ
category_keywords = {
    "ê·¼ë¬´ì¼ë°˜": [
        "ì¶œê·¼", "í‡´ê·¼", "ê·¼ë¬´ì‹œê°„", "ìœ ì—°ê·¼ë¬´", "ì§€ê°", "ê²°ê·¼", "ì¡°í‡´",
        "ì¬íƒ", "ì™¸ê·¼", "ê·¼ë¬´ë³µì¥", "ê·¼ë¬´ì œë„", "ì‹œì°¨ì¶œê·¼", "ì—°ì¥ê·¼ë¬´",
        "ì‚¬ë‚´ê·œì •", "ì¼ë°˜ê·œì •", "ë§¤ë‰´ì–¼", "ì§ë¬´ê·œì¹™", "ì„œì•½ì„œ"
    ],
    "ê¸‰ì—¬ë³´ìƒ": [
        "ê¸‰ì—¬", "ì›”ê¸‰", "ì„ê¸ˆ", "ì—°ë´‰", "ë³´ë„ˆìŠ¤", "ì„±ê³¼ê¸‰", "ìƒì—¬",
        "ì¸ì„¼í‹°ë¸Œ", "ìˆ˜ë‹¹", "í‡´ì§ê¸ˆ", "ì—°ë§ì •ì‚°", "ê¸‰ì—¬ì¼", "ì„¸ê¸ˆ",
        "ì§€ê¸‰ì¼", "ê¸‰ì—¬ëª…ì„¸ì„œ", "ì„¸ìœ¨", "ì†Œë“", "ë³´ìƒì œë„"
    ],
    "ë³µë¬´": [
        "ì—°ì°¨", "ë°˜ì°¨", "ë³‘ê°€", "ê³µê°€", "íœ´ì§", "ë¬´ê¸‰íœ´ê°€", "íŠ¹ë³„íœ´ê°€",
        "ëŒ€ì²´íœ´ê°€", "ìƒë¦¬íœ´ê°€", "ê²°ê·¼", "ìœ ê¸‰", "ì§€ê°", "ì¡°í‡´",
        "ë³µë¬´", "ì¶œê²°ì²˜ë¦¬", "ê·¼íƒœ", "ì¶œì„", "ì—…ë¬´ë³µê·€", "íœ´ê°€ì‚¬ìš©", "ìƒì¼", 
    ],
    "ë³µì§€ì œë„": [
        "ë³µì§€", "ê±´ê°•ê²€ì§„", "ì‹ëŒ€", "ëª…ì ˆì„ ë¬¼", "ê²½ì¡°ì‚¬ë¹„", "ë™í˜¸íšŒ", "ì¥ê¸°ê·¼ì†",
        "ìê¸°ê³„ë°œ", "ì‚¬ë‚´ë³µì§€", "ë¦¬í”„ë ˆì‹œ", "ì›Œë¼ë°¸", "ë²•ì¸íœ´ì–‘ì†Œ", "ë°°ìš°ì","ë°°ìš°ìì¶œì‚°","ê²½ì¡°ì§€ì›ê¸ˆ",
        "ê¸°í”„í‹°ì½˜", "ê°„ì‹", "í—¬ìŠ¤", "ìƒí™œë¹„ì§€ì›", "ìƒì¼ì„ ë¬¼", "ìŠ¾ë¨¸ë‹ˆ", "ê²½ì¡°íœ´ê°€", "ì¶œì‚°íœ´ê°€"
    ],
    "ì—…ë¬´ì§€ì›ê²½ë¹„": [
        "ì¥ë¹„", "ë…¸íŠ¸ë¶", "ë°ìŠ¤í¬íƒ‘", "ì†Œí”„íŠ¸ì›¨ì–´", "ê³„ì •", "ë©”ì¼",
        "ì„¤ì¹˜", "ë°˜ë‚©", "VPN", "êµ¬ì…", "ì²­êµ¬", "ë²•ì¸ì¹´ë“œ", "ë¹„ìš©ì •ì‚°",
        "ì—…ë¬´ë¹„", "ì¶œì¥ë¹„", "ì¦ë¹™", "êµ¬ë§¤ìš”ì²­", "ì˜ìˆ˜ì¦"
    ],
    "ì±„ìš©ì˜¨ë³´ë”©": [
        "ì±„ìš©", "ì…ì‚¬", "í•©ê²©", "ë©´ì ‘", "ì „í˜•", "ì´ë ¥ì„œ", "ê²½ë ¥", "ì‹ ì…",
        "ì˜¨ë³´ë”©", "ì…ì‚¬ì¼", "ì±„ìš©ì ˆì°¨", "ì±„ìš©ì„œë¥˜", "ë³µìˆ˜í•©ê²©",
        "ì…ì‚¬ ì „ ì•ˆë‚´", "ê·¼ë¡œê³„ì•½", "ê³„ì •ìƒì„±", "ì‚¬ë²ˆ", "ì¶œê·¼ì¼"
    ]
}

def classify_question(question):
    for category, keywords in category_keywords.items():
        if any(keyword in question for keyword in keywords):
            return category
    return "ê·¼ë¬´ì¼ë°˜"

# âœ… Notion í…ìŠ¤íŠ¸ ìˆ˜ì§‘
def get_notion_text(page_id):
    try:
        children = collect_paginated_api(notion.blocks.children.list, block_id=page_id)
        texts = []
        for child in children:
            rich = child.get(child["type"], {}).get("rich_text", [])
            for part in rich:
                texts.append(part.get("plain_text", ""))
        return "\n".join(texts)
    except Exception as e:
        print("âš ï¸ Notion ì˜¤ë¥˜:", e)
        return ""

# âœ… íŠ¹ì • ì‹œíŠ¸ì—ì„œë§Œ ë¶ˆëŸ¬ì˜¤ê¸° (ì¹´í…Œê³ ë¦¬ë³„)
from langchain.schema import Document

# âœ… get_sheet_data_by_category: try ~ except êµ¬ì¡° ì™„ì„±
def get_sheet_data_by_category(category):
    try:
        sheet_range = f"'{category}'!A1:Z1000" if "." in category else f"{category}!A1:Z1000"
        credentials = service_account.Credentials.from_service_account_info(
            json.loads(st.secrets["GOOGLE_CREDENTIALS"]),
            scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"]
        )
        service = build("sheets", "v4", credentials=credentials)
        result = service.spreadsheets().values().get(
            spreadsheetId=SPREADSHEET_ID,
            range=sheet_range
        ).execute()
        values = result.get("values", [])

        if values:
           return [
                Document(
                    page_content=row[1],
                    metadata={"source": category, "question": row[0]}
                )
                for row in values if len(row) > 1
            ]

        else:
            return []

    except Exception as e:
        print(f"âš ï¸ Sheets ì˜¤ë¥˜({category}):", e)
        return []

from difflib import get_close_matches

from difflib import SequenceMatcher

def find_fuzzy_match(user_q, sheet_docs):
    best_match = None
    highest_ratio = 0.0

    for doc in sheet_docs:
        question = doc.metadata.get("question", "")
        ratio = SequenceMatcher(None, user_q.strip().lower(), question.strip().lower()).ratio()

        if ratio == 1.0:
            # âœ… ì™„ì „ì¼ì¹˜ â†’ ì¦‰ì‹œ ë°˜í™˜
            return [doc]
        elif ratio >= 0.8 and ratio > highest_ratio:
            # âœ… 90% ì´ìƒ ìœ ì‚¬ â†’ ê°€ì¥ ìœ ì‚¬í•œ í•­ëª© ì €ì¥
            best_match = doc
            highest_ratio = ratio

    if best_match:
        return [best_match]

    return []

def contains_all_keywords(original: str, rewritten: str) -> bool:
    original_tokens = original.lower().split()
    return all(token in rewritten.lower() for token in original_tokens)

# âœ… ë°ì´í„° ìˆ˜ì§‘ ë° ì„ë² ë”©
documents = []
notion_text = get_notion_text(notion_page_id)

if notion_text:
    documents.append(Document(page_content=notion_text))

# âœ… (ì´ì œëŠ” get_sheet_data()ë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ!)

if not documents:
    st.error("â— ë°ì´í„° ì—†ìŒ: Notion ë˜ëŠ” Google Sheets ì—°ê²° í™•ì¸")
    st.stop()

# âœ… ë¬¸ì„œ ìª¼ê°œê¸°
splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=100)
docs = splitter.split_documents(documents)

# âœ… ë²¡í„° ì €ì¥ì†Œ ë° ì„ë² ë”©
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
vectorstore = DocArrayInMemorySearch.from_documents(docs, embeddings)
retriever = vectorstore.as_retriever(search_kwargs={"k": 1})

# âœ… filter ì •ì˜ë„ í•„ìš”:
filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)
compressed_retriever = ContextualCompressionRetriever(
    base_compressor=filter,
    base_retriever=retriever,
)

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.chains.llm import LLMChain
from langchain.chains.combine_documents.refine import RefineDocumentsChain

# âœ… ìµœì‹  ChatOpenAI ì‚¬ìš©
llm = ChatOpenAI(
    openai_api_key=openai_api_key,
    model_name="gpt-4-1106-preview",
    temperature=0.3,
    max_tokens=1024
)

# âœ… rewrite_chain ìœ„ì¹˜ëŠ” ì—¬ê¸°!!
rewrite_prompt = PromptTemplate(
    input_variables=["question"],
    template="""ë‹¹ì‹ ì€ HR ì œë„ì— ëŒ€í•´ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ íšŒì‚¬ ë‚´ë¶€ ë§¤ë‰´ì–¼ì—ì„œ ê²€ìƒ‰í•˜ê¸° ì í•©í•œ í˜•íƒœë¡œ ë‹¤ì‹œ ì¨ì£¼ì„¸ìš”. ë„ˆë¬´ ì§§ê±°ë‚˜ ëª¨í˜¸í•œ ì§ˆë¬¸ì´ë¼ë„ ì¸ì‚¬íŒ€ì— ë¬¼ì„ ë§Œí•œ í‘œí˜„ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë°”ê¾¸ì„¸ìš”.

ë”°ë¼ì„œ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ, íšŒì‚¬ì˜ ì¸ì‚¬ ë§¤ë‰´ì–¼, ë³µë¬´ ê·œì •, ë³µì§€ì œë„ ë“±ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ê¸° ì í•©í•œ í˜•íƒœë¡œ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.

- ê°€ëŠ¥í•œ í•œ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.
- ì§ˆë¬¸ìê°€ ë¬¼ì–´ë³´ëŠ” ì§ˆë¬¸ ì¤‘ ë‹¨ì–´ ë˜ëŠ” ê³ ìœ ëª…ì‚¬ë“¤ì˜ ê²½ìš° ë³„ë„ ê°€ê³µí•˜ì§€ ì•Šê³  ê²€ìƒ‰í•˜ëŠ” ì£¼ìš”í•œ í‚¤ì›Œë“œë¡œ ì‚¬ìš©í•´ì£¼ì„¸ìš”. ì˜ˆì‹œ - ìŠ¾ë¨¸ë‹ˆ, ë°°ìš°ìì¶œì‚°íœ´ê°€ ë“±
- ì§ˆë¬¸ìê°€ ë¬¼ì–´ë³¸ ì§ˆë¬¸ì— ëŒ€í•´ ë…¸ì¶œí•  ë–„ëŠ” ê·¸ëŒ€ë¡œ ë…¸ì¶œë˜ê²Œ í•´ì£¼ì„¸ìš”. ì ˆëŒ€ ì§ˆë¬¸ìì˜ ì§ˆë¬¸ì„ ë§ˆìŒëŒ€ë¡œ ê°€ê³µí•´ì„œ ë…¸ì¶œì‹œí‚¤ì§€ë§ˆì„¸ìš”.
- ë‹µë³€ì˜ ì†ŒìŠ¤ì˜ ê²½ìš°, ì™¸ë¶€ì—ì„œ ì ˆëŒ€ë¡œ ê°€ì ¸ì˜¤ì§€ ë§ê³  ì œê³µëœ ë…¸ì…˜ê³¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ìˆëŠ” ê²ƒë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”. 
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì„ ì¶”ì¸¡í•˜ê±°ë‚˜ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë“±ì¥í•œ ë‹¨ì–´ëŠ” íŠ¹íˆ ê³ ìœ ëª…ì‚¬(ì˜ˆ: ìŠ¾ë¨¸ë‹ˆ, ë¶€ì„œëª…, ì œë„ëª… ë“±)ëŠ” ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ê³ , **ì² ì, ë„ì–´ì“°ê¸°, í˜•íƒœ ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ì„¸ìš”.
- ì˜ë¯¸ë¥¼ ìœ ì¶”í•˜ê±°ë‚˜ ì¼ë°˜í™”í•´ì„œ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. íŠ¹íˆ, ì‚¬ìš©ìê°€ ì˜¤íƒ€ë¥¼ í¬í•¨í•´ ì…ë ¥í•œ ê³ ìœ ëª…ì‚¬ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- ì˜ˆ: "ìŠ¾ë¨¸ë‹ˆ"ëŠ” "ìŠ¤í¿ë¨¸ë‹ˆ"ë¡œ ë°”ê¾¸ë©´ ì•ˆ ë©ë‹ˆë‹¤.
- ì§ˆë¬¸ ë¬¸ì¥ì€ ì „ì²´ì ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ë°”ê¾¸ë˜, **ì›ë¬¸ì˜ ëª…ì¹­(ê³ ìœ ëª…ì‚¬)ì€ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ì„¸ìš”.

ì˜ˆì‹œ:
ì…ë ¥: ë°°ìš°ì ì¶œì‚° íœ´ê°€ëŠ” ë©°ì¹ ?
â†’ ì¶œë ¥: ë°°ìš°ì ì¶œì‚° ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²½ì¡°íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?

ì…ë ¥: íœ´ê°€ ì¢…ë¥˜
â†’ ì¶œë ¥: íšŒì‚¬ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íœ´ê°€ì˜ ì¢…ë¥˜ì—ëŠ” ë¬´ì—‡ì´ ìˆë‚˜ìš”?

ì…ë ¥: ìƒì¼ ê´€ë ¨ ë³µì§€ ë­ ìˆì–´ìš”?
â†’ ì¶œë ¥: ìƒì¼ì— ì œê³µë˜ëŠ” ë³µì§€ í˜œíƒì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?

ì…ë ¥: ë³¸ì¸ ê²°í˜¼ ì‹œ ê²½ì¡°íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?
â†’ ì¶œë ¥: ë³¸ì¸ ê²°í˜¼ ì‹œ ì œê³µë˜ëŠ” ê²½ì¡°íœ´ê°€ íœ´ê°€ì¼ìˆ˜ëŠ” ë©°ì¹ ì¸ê°€ìš”?

---

ì‚¬ìš©ì ì§ˆë¬¸: {question}
ëª…í™•í•œ ì§ˆë¬¸:
"""
)
rewrite_chain = LLMChain(llm=llm, prompt=rewrite_prompt)

# âœ… Prompt êµ¬ì„±
question_prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""ë‹¤ìŒì€ íšŒì‚¬ì˜ ë‚´ë¶€ HR ì •ì±… ë¬¸ì„œì…ë‹ˆë‹¤. ì´ ë¬¸ì„œì— ê¸°ë°˜í•´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

â— ì¤‘ìš”í•œ ê·œì¹™:
- ë¬¸ì„œ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•˜ë©°, ì™¸ë¶€ ì§€ì‹ì´ë‚˜ ì¼ë°˜ ìƒì‹ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ë¬¸ì„œì— ëª…í™•í•œ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°, ë°˜ë“œì‹œ "ì œê³µëœ ìë£Œì— ì—†ìŠµë‹ˆë‹¤. HRíŒ€ì— ë¬¸ì˜í•´ì£¼ì„¸ìš”."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì„ ì¶”ë¡ í•˜ê±°ë‚˜ ìœ ì¶”í•˜ì§€ ë§ˆì„¸ìš”.
- "íšŒì‚¬ ì •ì±…ì— ë”°ë¼", "ê·¼ë¡œê¸°ì¤€ë²•ìƒ", "êµ­ê°€ë³„ë¡œ ë‹¤ë¥´ë‹¤" ê°™ì€ ë¬¸êµ¬ë„ ë¬¸ì„œì— ì—†ìœ¼ë©´ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

ë¬¸ì„œ:
{context}

ì§ˆë¬¸:
{question}

ë‹µë³€:"""
)

refine_prompt = PromptTemplate(
    input_variables=["existing_answer", "context", "question"],
    template="""ê¸°ì¡´ ë‹µë³€ì„ ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì„ ë°˜ì˜í•´ ë” ë‚˜ì€ ë‹µë³€ìœ¼ë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

â— ì£¼ì˜: ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ë³´ì™„í•˜ê±°ë‚˜ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
â— ë¬¸ì„œì— ê·¼ê±° ì—†ëŠ” ë‚´ìš©ì€ ì œê±°í•˜ê³ , ë¬¸ì„œì— í¬í•¨ëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

ê¸°ì¡´ ë‹µë³€: {existing_answer}

ì¶”ê°€ ë¬¸ì„œ: {context}

ì§ˆë¬¸: {question}
ìˆ˜ì •ëœ ë‹µë³€:"""
)

# âœ… LLM ì²´ì¸ êµ¬ì„±
initial_llm_chain = LLMChain(llm=llm, prompt=question_prompt)
refine_llm_chain = LLMChain(llm=llm, prompt=refine_prompt)

combine_documents_chain = RefineDocumentsChain(
    initial_llm_chain=initial_llm_chain,
    refine_llm_chain=refine_llm_chain,
    document_variable_name="context",
    initial_response_name="existing_answer"
)

# âœ… RetrievalQA
qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=compressed_retriever,
    chain_type="stuff",  # âœ… stuffë¡œ ë°”ê¾¸ê¸°
    return_source_documents=False,
    chain_type_kwargs={
        "prompt": question_prompt
    }
)

# âœ… Streamlit UI
st.set_page_config(page_title="ìŠ¤íŒŒí¬í”ŒëŸ¬ìŠ¤ HR ì±—ë´‡", layout="wide")
col1, col2, col3 = st.columns([1, 2, 1])

# âœ… col3: FAQ ë²„íŠ¼ í´ë¦­ ì‹œ ì§ˆë¬¸ ê¸°ë¡
with col3:
    st.markdown("### ğŸ“Œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
    faq_list = [
        "ë³¸ì¸ ê²°í˜¼ ì‹œ ê²½ì¡°íœ´ê°€ëŠ” ë©°ì¹ ì¸ê°€ìš”?",
        "ë³¸ì¸ ê²°í˜¼ ì‹œ ê²½ì¡°ì§€ì›ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "ë°°ìš°ì ì¶œì‚° ì‹œ ê²½ì¡°íœ´ê°€ëŠ”?",
        "ë¶€ëª¨ ì‚¬ë§ ì‹œ ê²½ì¡°íœ´ê°€ ì¼ìˆ˜ëŠ”?",
        "ìŠ¾ë¨¸ë‹ˆ ì§€ê¸‰ ê¸°ì¤€ì€?"
    ]
    for q in faq_list:
        if st.button(q):
            st.session_state.messages.append({"role": "user", "content": q})
            rewritten_input = rewrite_chain.run(q)
            if not contains_all_keywords(q, rewritten_input):
                rewritten_input = q
            st.session_state.faq_trigger = rewritten_input
            st.rerun()

# âœ… col2 ë‚´ë¶€
with col2:
    st.title("ğŸ˜€ ìŠ¤íŒŒí¬í”ŒëŸ¬ìŠ¤ HR ì±—ë´‡")
    st.markdown("<p style='font-size:16px; color: black;'>ìŠ¤íŒŒí¬í”ŒëŸ¬ìŠ¤ ì¸ì‚¬ì œë„ ë˜ëŠ” Employee Services ê´€ë ¨     ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš” ğŸ‘‡</p>", unsafe_allow_html=True)

    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.faq_trigger = None
        st.rerun()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "faq_trigger" not in st.session_state:
        st.session_state.faq_trigger = None

    # ê³¼ê±° ë©”ì‹œì§€ ì¶œë ¥
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # âœ… ì‚¬ìš©ì ì…ë ¥ì°½
    user_input = st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        rewritten_input = rewrite_chain.run(user_input)
        if not contains_all_keywords(user_input, rewritten_input):
            rewritten_input = user_input
        st.session_state.faq_trigger = rewritten_input
        st.rerun()


# âœ… col2 ë°”ê¹¥: ì§ˆë¬¸ ì²˜ë¦¬
q = None
if "faq_trigger" in st.session_state and st.session_state.faq_trigger:
    q = st.session_state.faq_trigger
    st.session_state.faq_trigger = None

if q:
    answer = ""
    selected_category = classify_question(q)
    sheet_documents = get_sheet_data_by_category(selected_category)

    # âœ… Step 0: ì‹œíŠ¸ ì§ˆë¬¸ ì •í™• ì¼ì¹˜ í™•ì¸
    for doc in sheet_documents:
        if doc.metadata["question"].strip() == q.strip():
            answer = doc.page_content.strip()
            answer += "\n\n[ğŸ”— ì œë„ìƒì„¸: ë°”ë¡œê°€ê¸°](https://zrr.kr/jBwxck)"
            st.session_state.messages.append({"role": "assistant", "content": answer})
            st.rerun()

    if sheet_documents:
        # Step 1: ìœ ì‚¬ ì§ˆë¬¸ ìš°ì„  ë§¤ì¹­
        fuzzy_match = find_fuzzy_match(q, sheet_documents)
        if fuzzy_match:
            answer = fuzzy_match[0].page_content.strip()
        else:
            # Step 2: GPT rewrite í›„ ê²€ìƒ‰
            rewritten_q = rewrite_chain.run(q)
            selected_category = classify_question(rewritten_q)
            sheet_documents = get_sheet_data_by_category(selected_category)

            if not sheet_documents:
                answer = "âŒ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HRíŒ€ì— ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            else:
                vectorstore = DocArrayInMemorySearch.from_documents(docs, embeddings)
                retriever = vectorstore.as_retriever(search_kwargs={"k": 1})

                # âœ… filter ì •ì˜ë„ í•„ìš”:
                filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)

                compressed_retriever = ContextualCompressionRetriever(
                    base_compressor=filter,
                    base_retriever=retriever,
                )
                retrieved_docs = compressed_retriever.get_relevant_documents(rewritten_q)

                if not retrieved_docs:
                    answer = "âŒ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HRíŒ€ì— ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                else:
                    raw_answer = qa.run(rewritten_q)

                    # âœ… ë§Œì•½ ë‹µë³€ì— "í•´ë‹¹ ë‚´ìš©ì€ ì œê³µëœ ìë£Œì— ì—†ìŠµë‹ˆë‹¤"ê°€ ì—†ë‹¤ë©´, ë¬´ì¡°ê±´ sheet ì²« ë¬¸ë‹¨ ì‚¬ìš©
                    if (
                        not raw_answer or
                        raw_answer.strip().lower() in ["i don't know.", "i do not know"] or
                        "ì œê³µëœ ìë£Œì— ì—†ìŠµë‹ˆë‹¤" not in raw_answer and len(raw_answer.strip()) < 50 or
                        "íšŒì‚¬ë§ˆë‹¤ ë‹¤ë¦…ë‹ˆë‹¤" in raw_answer or
                        "ë‚¨ë…€ê³ ìš©í‰ë“±ë²•" in raw_answer or 
                        "ê·¼ë¡œê¸°ì¤€ë²•" in raw_answer or 
                        "ë…¸ë™ë²•" in raw_answer or 
                        "íšŒì‚¬ ì •ì±…ì— ë”°ë¼" in raw_answer  # â† GPT ì™¸ë¶€ ì§€ì‹ ê¸°ë°˜ í‘œí˜„ í•„í„°ë§
                    ):
                        answer = retrieved_docs[0].page_content.strip()
                    elif raw_answer:
                        answer = raw_answer.strip()
                    else:
                        answer = "âŒ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HRíŒ€ì— ë¬¸ì˜í•´ì£¼ì„¸ìš”."

    # âœ… ë§í¬ ì¶”ê°€
    answer += "\n\n[ğŸ”— ì œë„ìƒì„¸: ë°”ë¡œê°€ê¸°](https://zrr.kr/jBwxck)"

    # âœ… ë‹µë³€ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": answer})
    st.rerun()
